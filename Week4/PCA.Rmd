---
title: "DATA SCIENCE AND ANALYTICS"
author: "Ayşe Ceren Çiçek"
output: 
  html_document: default
  pdf_document: default
  word_document: default
subtitle: Principle Component Analysis
font-family: Gill Sans
---

PCA is a type of linear transformation on a given data set that has values for a certain number of variables (coordinates) for a certain amount of spaces. This linear transformation fits this dataset to a new coordinate system in such a way that the most significant variance is found on the first coordinate, and each subsequent coordinate is orthogonal to the last and has a lesser variance. In this way, you transform a set of x correlated variables over y samples to a set of p uncorrelated principal components over the same samples.

## Importing Libraries

```{r}
#install_github("vqv/ggbiplot")
library(dplyr)
library(stats)
library(devtools)
library(ggbiplot)
```


## Loading the dataset

```{r}
data <- mtcars
head(data, n=5)
```


## Apply PCA

We reduced 11 dimentions to 9. 

```{r}
data.pca <- prcomp(mtcars[, c(1:7, 10, 11)], center = TRUE, scale. = TRUE)
summary(data.pca)
```

As seen above, PC1 explains 63% of the total variance, which means that nearly two-thirds of the information in the dataset (9 variables) can be encapsulated by just that one Principal Component.


```{r}
str(data.pca)
```


## Plot PCA

```{r}
ggbiplot(data.pca)
```

```{r}
ggbiplot(data.pca, labels=rownames(data))
```

The car names clustered together at the top are similar to each other.

```{r}
data.country <- c(rep("Japan", 3), rep("US",4), rep("Europe", 7),rep("US",3), "Europe", rep("Japan", 3), rep("US",4), rep("Europe", 3), "US", rep("Europe", 3))

ggbiplot(data.pca,ellipse=TRUE,  labels=rownames(data), groups=data.country)
```

